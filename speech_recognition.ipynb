{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is for developing the speech_recognition system\n",
    "from __future__ import unicode_literals\n",
    "import math\n",
    "import random\n",
    "import spacy\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import wave, sys, pyaudio\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voiceshell starting...\n"
     ]
    }
   ],
   "source": [
    "#this code was taken from the voiceshell.py program\n",
    "\n",
    "\"\"\"\n",
    "def roboVoice(statement):\n",
    "    engine = pyttsx3.init();\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', rate-25)\n",
    "    voices = engine.getProperty('voices')\n",
    "    engine.setProperty('voice', 'en-uk-rp')\n",
    "    engine.say(statement)\n",
    "    engine.runAndWait()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Voiceshell starting...\")\n",
    "# roboVoice(\"Ahem. Starting...\")\n",
    "def meanv(coords):\n",
    "    sumv = [0] * len(coords[0])\n",
    "    for item in coords:\n",
    "        for i in range(len(item)):\n",
    "            sumv[i] += item[i]\n",
    "    mean = [0] * len(sumv)\n",
    "    for i in range(len(sumv)):\n",
    "        mean[i] = float(sumv[i]) / len(coords)\n",
    "    return mean\n",
    "\n",
    "def cosine(v1, v2):\n",
    "    if norm(v1) > 0 and norm(v2) > 0:\n",
    "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def sentvec(s):\n",
    "    sent = nlp(s)\n",
    "    word_vectors = [w.vector for w in sent]\n",
    "    return meanv(word_vectors)\n",
    "\n",
    "def spacy_closest_sent(space, input_str, n=1):\n",
    "    input_vec = sentvec(input_str)\n",
    "    return sorted(space,\n",
    "                  key=lambda x: cosine(np.mean([w.vector for w in x], axis=0), input_vec), reverse=True)[:n]\n",
    "\n",
    "nlp = spacy.load('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text...\n",
      "Done.\n",
      "Starting up speech recognition...\n",
      "Calibrating microphone for ambient noise... (this will take 5 seconds)\n",
      "Done, starting program.\n"
     ]
    }
   ],
   "source": [
    "# more code taken from voiceshell.py\n",
    "print(\"Loading text...\")\n",
    "# roboVoice(\"Loading text files...\")\n",
    "corpusFile = 'voiceshell_audio_LUT.csv'\n",
    "\n",
    "with open(corpusFile, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    all_lines = list(reader)\n",
    "\n",
    "audio_lookup_table = {}\n",
    "sentences = []\n",
    "for line in all_lines:\n",
    "    sentence = line[0]\n",
    "    if not sentence.isspace():\n",
    "        sentences.append(nlp(sentence))\n",
    "    filename = line[1]\n",
    "    audio_lookup_table[sentence] = filename\n",
    "print(\"Done.\")\n",
    "# roboVoice(\"Starting speech recognition...\")\n",
    "print(\"Starting up speech recognition...\")\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Calibrating microphone for ambient noise... (this will take 5 seconds)\")\n",
    "    # roboVoice(\"Calibrating microphone for ambient noise... (this will take 5 seconds)\")\n",
    "    r.adjust_for_ambient_noise(source, duration=5)\n",
    "    print(\"Done, starting program.\")\n",
    "    # roboVoice(\"Done, starting program.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a higher value equates to less sensitivity, a lower value is more sensitive: 50-4000 are typical values\n",
    "# this is the manual way to adjust the sensitivity while adjust_for_ambiant_noise is the automatic way\n",
    "r.energy_threshold = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from voiceshell.py but now tries google if google is down then it uses sphinx\n",
    "def runLoop():\n",
    "    # roboVoice(\"I'm listening...\")\n",
    "    print(\"Say something!\")\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        audio = r.listen(source)\n",
    "    \n",
    "    # try with google first\n",
    "    try:\n",
    "        userInput = r.recognize_google(audio)\n",
    "        print(\"Google thinks you said : \", userInput)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition could not understand audio\")\n",
    "\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "        try:\n",
    "            userInput = r.recognize_sphinx(audio)\n",
    "            print(\"Sphinx thinks you said\")\n",
    "        except sr.UnknownValueError:\n",
    "            # roboVoice(\"Sorry, I couldn't understand that.\")\n",
    "            print(\"Sorry, I didn't understand that.\")\n",
    "        except sr.RequestError as e:\n",
    "            # roboVoice(\"Sphinx Error {0}\".format(e))\n",
    "            print(\"Sphinx recognition error; {0}\".format(e))\n",
    "    \n",
    "    matched = process.extractBests(userInput, sentences, score_cutoff = 60)\n",
    "\n",
    "    if(userInput == 'open the pod bay doors'):\n",
    "        audioFile = 'Audio/sorry.wav'\n",
    "\n",
    "    elif not matched:\n",
    "        for sent in spacy_closest_sent(sentences, userInput):\n",
    "            output = sent.text\n",
    "            print(output)\n",
    "\n",
    "        audioFile = audio_lookup_table[output]\n",
    "        print(audioFile)\n",
    "\n",
    "    else:\n",
    "        output = random.choice(matched)\n",
    "        cleaned_output = str(output[0])\n",
    "        print(cleaned_output)\n",
    "\n",
    "        audioFile = audio_lookup_table[cleaned_output]\n",
    "        print(audioFile)\n",
    "\n",
    "    sound = wave.open(audioFile)\n",
    "    p = pyaudio.PyAudio()\n",
    "    chunk = 1024\n",
    "    stream = p.open(format = p.get_format_from_width(sound.getsampwidth()), channels = sound.getnchannels(), rate = sound.getframerate(), output = True)\n",
    "    data = sound.readframes(chunk)\n",
    "    while len(data) > 0:\n",
    "        stream.write(data)\n",
    "        data = sound.readframes(chunk)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n",
      "you said :  that will have\n",
      "But his eyes are so glad-pale-lashed, green eyes- that I forget to question his awareness.\n",
      "Audio/AmyBrown/AmyBrown42.wav\n",
      "Say something!\n",
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n",
      "you said :  if that\n",
      "like scales that tilt toward injustice.\n",
      "Audio/BobOrr/BobOrr7.wav\n",
      "Say something!\n",
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n",
      "you said :  okay i can sing something now\n",
      "At times I hate my wide painted eyes, though I'm becoming wiser.\n",
      "Audio/AmyBrown/AmyBrown26.wav\n",
      "Say something!\n",
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n",
      "you said :  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-91426d956b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrunLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b38ba6e91a89>\u001b[0m in \u001b[0;36mrunLoop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspacy_closest_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-91aa473508ed>\u001b[0m in \u001b[0;36mspacy_closest_sent\u001b[0;34m(space, input_str, n)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspacy_closest_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0minput_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     return sorted(space,\n\u001b[1;32m     40\u001b[0m                   key=lambda x: cosine(np.mean([w.vector for w in x], axis=0), input_vec), reverse=True)[:n]\n",
      "\u001b[0;32m<ipython-input-21-91aa473508ed>\u001b[0m in \u001b[0;36msentvec\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmeanv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspacy_closest_sent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-91aa473508ed>\u001b[0m in \u001b[0;36mmeanv\u001b[0;34m(coords)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# roboVoice(\"Ahem. Starting...\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeanv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msumv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    runLoop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "new_Decoder returned -1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-15fc9fefb9c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Process audio chunk by chunk. On keyword detected perform action and restart search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_utt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nathan/.pyenv/versions/3.5.1/Python.framework/Versions/3.5/lib/python3.5/site-packages/pocketsphinx/pocketsphinx.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDecoder\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfig\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \"\"\"\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mthis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pocketsphinx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_Decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: new_Decoder returned -1"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pocketsphinx.pocketsphinx import *\n",
    "from sphinxbase.sphinxbase import *\n",
    "import pyaudio\n",
    "\n",
    "modeldir = \"../../../model\"\n",
    "datadir = \"../../../test/data\"\n",
    "\n",
    "# Create a decoder with certain model\n",
    "config = Decoder.default_config()\n",
    "config.set_string('-hmm', os.path.join(modeldir, 'en-us/en-us'))\n",
    "config.set_string('-dict', os.path.join(modeldir, 'en-us/cmudict-en-us.dict'))\n",
    "config.set_string('-keyphrase', 'forward')\n",
    "config.set_float('-kws_threshold', 1e+20)\n",
    "\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=1024)\n",
    "stream.start_stream()\n",
    "\n",
    "# Process audio chunk by chunk. On keyword detected perform action and restart search\n",
    "decoder = Decoder(config)\n",
    "decoder.start_utt()\n",
    "while True:\n",
    "    buf = stream.read(1024)\n",
    "    if buf:\n",
    "         decoder.process_raw(buf, False, False)\n",
    "    else:\n",
    "         break\n",
    "    if decoder.hyp() != None:\n",
    "        print ([(seg.word, seg.prob, seg.start_frame, seg.end_frame) for seg in decoder.seg()])\n",
    "        print (\"Detected keyword, restarting search\")\n",
    "        decoder.end_utt()\n",
    "        decoder.start_utt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Could not request results from Google Speech Recognition service; recognition connection failed: [Errno 8] nodename nor servname provided, or not known\n"
     ]
    }
   ],
   "source": [
    "# google's system works much better, I think we should try that \n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "    \n",
    "try:\n",
    "    # for testing purposes, we're just using the default API key\n",
    "    # to use another API key, use `r.recognize_google(audio, key=\"GOOGLE_SPEECH_RECOGNITION_API_KEY\")`\n",
    "    # instead of `r.recognize_google(audio)`\n",
    "    print(\"Google Speech Recognition thinks you said \" + r.recognize_google(audio))\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
